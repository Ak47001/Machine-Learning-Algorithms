{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.\tObtain the hypothesis space search by Find-S for the given training examples.\n",
    "sky=['sunny','sunny','rainy','sunny']\n",
    "airtemp=['warm','warm','cold','warm']\n",
    "hum=['normal','high','high','high']\n",
    "wind=['strong','strong','strong','strong']\n",
    "water=['warm','warm','warm','cool']\n",
    "fc=['same','same','change','change']\n",
    "esport=['yes','yes','no','yes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data={\"Sky\":sky,\"Airtemp\":airtemp,'Humidity':hum,'Wind':wind,'Water':water,'Forecast':fc,'Enjoysport':esport}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('sport.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the maximally hypothesis  is: ['sunny', 'warm', '?', 'strong', '?', '?']\n"
     ]
    }
   ],
   "source": [
    "#initial value of hypothesis\n",
    "h=['0']*6\n",
    "for instance in df.values:\n",
    "    if instance[-1]=='yes':\n",
    "        for j in range(len(h)):\n",
    "            if (h[j]=='0' or h[j]==instance[j]):\n",
    "                h[j]=instance[j]\n",
    "            elif h[j]!=instance[j]:\n",
    "                h[j]='?'\n",
    "print(\"the maximally hypothesis  is:\",h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.Apply Candidate Elimination Algorithm for the given training examples to obtain a hypothesis space. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "with open('sport.csv')  as csvFile:\n",
    "        examples = [tuple(line[1:]) for line in csv.reader(csvFile)]\n",
    "examples=examples[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('sunny', 'warm', 'normal', 'strong', 'warm', 'same', 'yes'),\n",
       " ('sunny', 'warm', 'high', 'strong', 'warm', 'same', 'yes'),\n",
       " ('rainy', 'cold', 'high', 'strong', 'warm', 'change', 'no'),\n",
       " ('sunny', 'warm', 'high', 'strong', 'cool', 'change', 'yes')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def g_0(n):\n",
    "    return (\"?\",)*n\n",
    "\n",
    "def s_0(n):\n",
    "    return ('0',)*n\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def more_general(h1, h2):\n",
    "    more_general_parts = []\n",
    "    for x, y in zip(h1, h2):\n",
    "        mg = x == \"?\" or (x != \"0\" and (x == y or y == \"0\"))\n",
    "        more_general_parts.append(mg)\n",
    "    return all(more_general_parts)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fulfills(example, hypothesis):\n",
    "    ### the implementation is the same as for hypotheses:\n",
    "    return more_general(hypothesis, example)\n",
    "\n",
    "def min_generalizations(h, x):\n",
    "    h_new = list(h)\n",
    "    for i in range(len(h)):\n",
    "        if not fulfills(x[i:i+1], h[i:i+1]):\n",
    "            h_new[i] = '?' if h[i] != '0' else x[i]\n",
    "    return [tuple(h_new)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_specializations(h, domains, x):\n",
    "    results = []\n",
    "    for i in range(len(h)):\n",
    "        if h[i] == \"?\":\n",
    "            for val in domains[i]:\n",
    "                if x[i] != val:\n",
    "                    h_new = h[:i] + (val,) + h[i+1:]\n",
    "                    results.append(h_new)\n",
    "        elif h[i] != \"0\":\n",
    "            h_new = h[:i] + ('0',) + h[i+1:]\n",
    "            results.append(h_new)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_domains(examples):\n",
    "    d = [set() for i in examples[0]]\n",
    "    for x in examples:\n",
    "        for i, xi in enumerate(x):\n",
    "            d[i].add(xi)\n",
    "    return [list(sorted(x)) for x in d]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generalize_S(x, G, S):\n",
    "    S_prev = set(S)\n",
    "    for s in S_prev:\n",
    "        if s not in S:\n",
    "            continue\n",
    "        if not fulfills(x, s):\n",
    "            S.remove(s)\n",
    "            Splus = min_generalizations(s, x)\n",
    "            ## keep only generalizations that have a counterpart in G\n",
    "            S.update([h for h in Splus if any([more_general(g,h) \n",
    "                                               for g in G])])\n",
    "            ## remove hypotheses less specific than any other in S\n",
    "            S.difference_update([h for h in S if \n",
    "                                 any([more_general(h, h1) \n",
    "                                      for h1 in S if h != h1])])\n",
    "    return S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def specialize_G(x, domains, G, S):\n",
    "    G_prev = list(G)\n",
    "    for g in G_prev:\n",
    "        if g not in G:\n",
    "            continue\n",
    "        if fulfills(x, g):\n",
    "            G.remove(g)\n",
    "            Gminus = min_specializations(g, domains, x)\n",
    "            ## keep only specializations that have a conuterpart in S\n",
    "            G.update([h for h in Gminus if any([more_general(h, s)\n",
    "                                                for s in S])])\n",
    "            ## remove hypotheses less general than any other in G\n",
    "            G.difference_update([h for h in G if \n",
    "                                 any([more_general(g1, h) \n",
    "                                      for g1 in G if h != g1])])\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def candidate_elimination(examples):\n",
    "    domains = get_domains(examples)[:-1]\n",
    "    \n",
    "    G = set([g_0(len(domains)-1)])\n",
    "    S = set([s_0(len(domains)-1)])\n",
    "    i=0\n",
    "    print(\"\\n G[{0}]:\".format(i),G)\n",
    "    print(\"\\n S[{0}]:\".format(i),S)\n",
    "    for xcx in examples:\n",
    "        i=i+1\n",
    "        x, cx = xcx[:-1], xcx[-1]  # Splitting data into attributes and decisions\n",
    "        if cx=='yes': # x is positive example\n",
    "            G = {g for g in G if fulfills(x, g)}\n",
    "            S = generalize_S(x, G, S)\n",
    "        else: # x is negative example\n",
    "            S = {s for s in S if not fulfills(x, s)}\n",
    "            G = specialize_G(x, domains, G, S)\n",
    "        print(\"\\n G[{0}]:\".format(i),G)\n",
    "        print(\"\\n S[{0}]:\".format(i),S)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " G[0]: {('?', '?', '?', '?', '?')}\n",
      "\n",
      " S[0]: {('0', '0', '0', '0', '0')}\n",
      "\n",
      " G[1]: {('?', '?', '?', '?', '?')}\n",
      "\n",
      " S[1]: {('sunny', 'warm', 'normal', 'strong', 'warm')}\n",
      "\n",
      " G[2]: {('?', '?', '?', '?', '?')}\n",
      "\n",
      " S[2]: {('sunny', 'warm', '?', 'strong', 'warm')}\n",
      "\n",
      " G[3]: {('?', 'warm', '?', '?', '?'), ('sunny', '?', '?', '?', '?')}\n",
      "\n",
      " S[3]: {('sunny', 'warm', '?', 'strong', 'warm')}\n",
      "\n",
      " G[4]: {('?', 'warm', '?', '?', '?'), ('sunny', '?', '?', '?', '?')}\n",
      "\n",
      " S[4]: {('sunny', 'warm', '?', 'strong', '?')}\n"
     ]
    }
   ],
   "source": [
    "candidate_elimination(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['no', 'no', 'yes', 'yes', 'yes', 'no', 'yes', 'no', 'yes', 'yes',\n",
       "       'yes', 'yes', 'yes', 'no'], dtype=object)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#3.Use ID3 Algorithm to develop the decision tree support system for the following training data set.\n",
    "df2=pd.read_csv(\"sport1.csv\")\n",
    "dataset=pd.read_csv('sport1.csv')\n",
    "dataset=dataset.iloc[:,1:6]\n",
    "X=dataset.iloc[:,0:4].values\n",
    "y=dataset.iloc[:,-1].values\n",
    "X\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#categorical data\n",
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder\n",
    "labelencoder_X=LabelEncoder()\n",
    "X[:,0]=labelencoder_X.fit_transform(X[:,0])\n",
    "X[:,1]=labelencoder_X.fit_transform(X[:,1])\n",
    "X[:,2]=labelencoder_X.fit_transform(X[:,2])\n",
    "X[:,3]=labelencoder_X.fit_transform(X[:,3])\n",
    "labelencoder_y=LabelEncoder()\n",
    "y=labelencoder_y.fit_transform(y)\n",
    "#print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the dataset into the training set and test set\n",
    "#model_selection=cross_validation\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=0)\n",
    "#'sunny','cool','high','strong'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#feature scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc=StandardScaler()\n",
    "X_train=sc.fit_transform(X_train)#it will learn and transform\n",
    "X_test=sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "                       max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=0, splitter='best')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fitting Decision Tree classififcation to the training set\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "classifier=DecisionTreeClassifier(criterion='entropy',random_state=0)\n",
    "classifier.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "tree.plot_tree(classifier.fit(X_train, y_train))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4.Data set given in the table is for a company produce tissues (used by biological labs). \n",
    "#Company objective is to predict how well their products are accepted by the clients. They conducted a survey with their clients to find the acceptance levels of the products.\n",
    "#As shown in figure, Type- 1 and 2 are not well accepted whereas Type- 3 and 4 are well accepted. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "X=np.array( [[7,7],\n",
    "    [7,4],\n",
    "    [3,4],\n",
    "    [1,4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=np.array([\"BAD\",\"BAD\",\"GOOD\",\"GOOD\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test = train_test_split(X,y,test_size=0.1,random_state =0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=2, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors = 2)\n",
    "knn.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['BAD'], dtype='<U4')"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = knn.predict(np.array([[3,7]]))\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0],\n",
       "       [1, 0]], dtype=int64)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test,y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['BAD']\n"
     ]
    }
   ],
   "source": [
    "print (knn.predict([[1,4]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5.Apply the naive Bayes classifier to a concept learning problem to classify days according to whether someone will \n",
    "#play tennis. The table given below provides a set of 14 training examples of the target concept PlayTennis, \n",
    "#where each day is described by the attributes Outlook, Temperature, Humidity, and Wind. \n",
    "sky=['sunny','sunny','overcast','rain','rain','rain','overcast','sunny','sunny','rain','sunny','overcast','overcast','rain']\n",
    "airtemp=['hot','hot','hot','mild','cool','cool','cool','mild','cool','mild','mild','mild','hot','mild']\n",
    "hum=['high','high','high','high','normal','normal','normal','high','normal','normal','normal','high','normal','high']\n",
    "wind=['weak','strong','weak','weak','weak','strong','strong','weak','weak','weak','strong','strong','weak','strong']\n",
    "esport=['no','no','yes','yes','yes','no','yes','no','yes','yes','yes','yes','yes','no']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data={\"sky\":sky,'airtemp':airtemp,'humidity':hum,'wind':wind,'Enjoy sport':esport}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "df1=pd.DataFrame(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_csv('sport1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Naives Bayes classification\n",
    "\n",
    "#importing libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the dataset\n",
    "dataset=pd.read_csv('sport1.csv')\n",
    "dataset=dataset.iloc[:,1:6]\n",
    "X=dataset.iloc[:,0:4].values\n",
    "y=dataset.iloc[:,-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object\n",
      "[0 0 1 1 1 0 1 0 1 1 1 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "#categorical data\n",
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder\n",
    "labelencoder_X=LabelEncoder()\n",
    "X[:,0]=labelencoder_X.fit_transform(X[:,0])\n",
    "X[:,1]=labelencoder_X.fit_transform(X[:,1])\n",
    "X[:,2]=labelencoder_X.fit_transform(X[:,2])\n",
    "X[:,3]=labelencoder_X.fit_transform(X[:,3])\n",
    "#onehotencoder=OneHotEncoder(categorical_features=[0,1,2,3])\n",
    "#X=onehotencoder.fit_transform(X).toarray()\n",
    "print(X.dtype)\n",
    "labelencoder_y=LabelEncoder()\n",
    "y=labelencoder_y.fit_transform(y)\n",
    "print(y)\n",
    "#if there is more than three value we can use hotencoder\n",
    "#[2,0,0,0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the dataset into the training set and test set\n",
    "#model_selection=cross_validation\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.01,random_state=0)\n",
    "#['sunny','cool','high','strong']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.27475488, -1.53960072,  1.08012345,  0.9258201 ]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#feature scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc=StandardScaler()\n",
    "X_train=sc.fit_transform(X_train)#it will learn and transform\n",
    "#X_test=[2,0,0,0]\n",
    "X_test=sc.transform(X_test)\n",
    "len(X_test)\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fitting Naives Bayes classififcation to the training set\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "classifier=GaussianNB()\n",
    "classifier.fit(X_train,y_train)\n",
    "#X_test=np.array([2,0,0,0])\n",
    "#Predicting the test set results\n",
    "y_pred=classifier.predict(X_test)\n",
    "y_pred=classifier.predict(np.array([[2,0,0,0]]))#sunny,cool,high,strong\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#6.\tDevelop a Decision Tree for the given data set and find the accuracy of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=pd.read_csv(\"Social_Network_Ads.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df2.iloc[:,[2,3]].values\n",
    "y=df2.iloc[:,4].values\n",
    "#df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the dataset into the training set and test set\n",
    "#model_selection=cross_validation\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.25,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc=StandardScaler()\n",
    "X_train=sc.fit_transform(X_train)#it will learn and transform\n",
    "X_test=sc.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "                       max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=0, splitter='best')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fitting Decision tree classififcation to the training set\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "classifier=DecisionTreeClassifier(criterion=\"entropy\",random_state=0)\n",
    "classifier.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicting the test set results\n",
    "y_pred=classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.91"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "sklearn.metrics.accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#7.\tDevelop a Naïve Bayes Classifier for the given data set and find the accuracy of the model.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "df=pd.read_csv(\"Social_Network_Ads.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df2.iloc[:,[2,3]].values\n",
    "y=df2.iloc[:,4].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the dataset into the training set and test set\n",
    "#model_selection=cross_validation\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.25,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc=StandardScaler()\n",
    "X_train=sc.fit_transform(X_train)#it will learn and transform\n",
    "X_test=sc.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fitting Naives Bayes classififcation to the training set\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "classifier=GaussianNB()\n",
    "classifier.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicting the test set results\n",
    "y_pred=classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "sklearn.metrics.accuracy_score(y_pred,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#8.\tDevelop a Logistic Regression classifier for the given data set and find the accuracy of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\New folder (2)\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier=LogisticRegression()\n",
    "classifier.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicting the test set results\n",
    "y_pred=classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.89"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "sklearn.metrics.accuracy_score(y_pred,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#9.\tDevelop a K-NN model for the given data set and find the accuracy of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "classifier=KNeighborsClassifier()\n",
    "classifier.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicting the test set results\n",
    "y_pred=classifier.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.93\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[62,  1],\n",
       "       [ 6, 31]], dtype=int64)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "print(sklearn.metrics.accuracy_score(y_pred,y_test))\n",
    "cm=sklearn.metrics.confusion_matrix(y_pred,y_test)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.93\n",
      "Misclassification: 0.06999999999999995\n",
      "type1 error: 0.16216216216216217\n",
      "type2 error: 0.015873015873015872\n",
      "sensitivity: 0.9117647058823529\n",
      "specifivity: 0.96875\n"
     ]
    }
   ],
   "source": [
    "#18.\tWrite the  Python code to calculate the following\n",
    "#a.\tAccuracy \n",
    "#b.\tMisclassification  \n",
    "#c.\tType-1 and Type-2 error rates\n",
    "#d.\tSensitivity\n",
    "#e.\tSpecificity\n",
    "Accuracy=(cm[0,0]+cm[1,1])/(cm[0,0]+cm[0,1]+cm[1,0]+cm[1,1])\n",
    "Misclassification=1-Accuracy\n",
    "type1er=cm[1,0]/(cm[1,0]+cm[1,1]) #FP rate\n",
    "type2er=cm[0,1]/(cm[0,0]+cm[0,1]) #FN rate\n",
    "sensitivity=(cm[0,0])/(cm[0,0]+cm[1,0]) #recall or true positive rate\n",
    "specifivity=(cm[1,1])/(cm[1,1]+cm[0,1]) #true negativity rate\n",
    "print(\"Accuracy:\",Accuracy)\n",
    "print(\"Misclassification:\",Misclassification)\n",
    "print(\"type1 error:\",type1er)\n",
    "print(\"type2 error:\",type2er)\n",
    "print(\"sensitivity:\",sensitivity)\n",
    "print(\"specifivity:\",specifivity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#10.\tDevelop a linear regression for the given data set and find the accuracy of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df2.iloc[:,[2,3]].values\n",
    "y=df2.iloc[:,4].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the dataset into the training set and test set\n",
    "#model_selection=cross_validation\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.25,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "classifier=LinearRegression()\n",
    "classifier.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #rom sklearn.decomposition import PCA as p\n",
    "# pc=p(n_components=1)\n",
    "# X_train=pc.fit_transform(X_train)\n",
    "# X_test=pc.transform(X_test)\n",
    "# #X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicting the test set results\n",
    "y_pred=classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import sklearn\n",
    "#sklearn.metrics.accuracy_score(y_pred,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#12.Develop a random forest for the given data set and find the accuracy of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\New folder (2)\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier=RandomForestClassifier()\n",
    "classifier.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.93"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.accuracy_score(y_pred,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#13.Compare the performance of all the classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\New folder (2)\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "E:\\New folder (2)\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "E:\\New folder (2)\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "E:\\New folder (2)\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "E:\\New folder (2)\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "E:\\New folder (2)\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "E:\\New folder (2)\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "E:\\New folder (2)\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "E:\\New folder (2)\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "E:\\New folder (2)\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "E:\\New folder (2)\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.637500 (0.243734)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\New folder (2)\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "E:\\New folder (2)\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "E:\\New folder (2)\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "E:\\New folder (2)\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "E:\\New folder (2)\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "E:\\New folder (2)\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "E:\\New folder (2)\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "E:\\New folder (2)\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "E:\\New folder (2)\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFA: 0.865000 (0.081548)\n",
      "KNN: 0.762500 (0.129542)\n",
      "CART: 0.855000 (0.092060)\n",
      "NB: 0.857500 (0.098139)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\New folder (2)\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "E:\\New folder (2)\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "E:\\New folder (2)\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "E:\\New folder (2)\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "E:\\New folder (2)\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "E:\\New folder (2)\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "E:\\New folder (2)\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "E:\\New folder (2)\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "E:\\New folder (2)\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "E:\\New folder (2)\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM: 0.667500 (0.213029)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compare Algorithms\n",
    "import pandas\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "# load dataset\n",
    "df2=pd.read_csv('Social_Network_Ads.csv')\n",
    "X=df2.iloc[:,[2,3]].values\n",
    "y=df2.iloc[:,4].values\n",
    "# prepare configuration for cross validation test harness\n",
    "seed = 7\n",
    "# prepare models\n",
    "models = []\n",
    "models.append(('LR', LogisticRegression()))\n",
    "models.append(('RFA', RandomForestClassifier()))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('CART', DecisionTreeClassifier()))\n",
    "models.append(('NB', GaussianNB()))\n",
    "models.append(('SVM', SVC()))\n",
    "# evaluate each model in turn\n",
    "results = []\n",
    "names = []\n",
    "scoring = 'accuracy'\n",
    "for name, model in models:\n",
    "    kfold = model_selection.KFold(n_splits=10, random_state=seed)\n",
    "    cv_results = model_selection.cross_val_score(model, X, y, cv=kfold, scoring=scoring)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)\n",
    "# boxplot algorithm comparison\n",
    "fig = plt.figure()\n",
    "fig.suptitle('Algorithm Comparison')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#14.Write the Python code to compute entropy and information gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"sport1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "c=0\n",
    "y=0\n",
    "n=0\n",
    "for i in df.values:\n",
    "    c=c+1\n",
    "    if i[-1]=='yes':\n",
    "        y=y+1\n",
    "    else:\n",
    "        n=n+1\n",
    "tot_wt=-((y/c)*(np.log10(y/c)/np.log10(2))+(n/c)*(np.log10(n/c)/np.log10(2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9402859586706309"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p=len(df)\n",
    "tot_wt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def entropy(s):\n",
    "    c=0\n",
    "    y=0\n",
    "    n=0\n",
    "    for i in s.values:\n",
    "        c=c+1\n",
    "        if i[-1]=='yes':\n",
    "            y=y+1\n",
    "        else:\n",
    "            n=n+1\n",
    "        #print(\"tot\",c)\n",
    "        #print(\"yes\",y)\n",
    "        if n==0:\n",
    "            j=0\n",
    "        else:\n",
    "            j=(n/c)*(np.log10(n/c)/np.log10(2))\n",
    "        if y==0:\n",
    "            k=0\n",
    "        else:\n",
    "            k=(y/c)*(np.log10(y/c)/np.log10(2))\n",
    "    return -(j+k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def information_gain(s,colname):\n",
    "    g=0\n",
    "    for i in np.unique(df[colname].values):\n",
    "        l=len(s[s[colname]==i])\n",
    "        g=g+(l/p)*entropy(s[s[colname]==i])\n",
    "    return tot_wt-g\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.246749819774439\n",
      "0.029222565658954647\n",
      "0.15183550136234147\n",
      "0.04812703040826927\n"
     ]
    }
   ],
   "source": [
    "for i in df.columns[:-1]:\n",
    "    print(information_gain(df,i))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#15.Write the  Python code todemonstrate conditional probability "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob(l,a,k):\n",
    "    n=len(df[df[l]==a][df['Enjoy sport']==k])\n",
    "    k=len(df[df[l]==a])\n",
    "    return n/k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\New folder (2)\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0413265306122449\n",
      "0.027551020408163266\n",
      "0.0413265306122449\n",
      "is going to play\n"
     ]
    }
   ],
   "source": [
    "def naive_bayes(s,c,h,m):\n",
    "    yc=len(df[df['Enjoy sport']=='yes'])\n",
    "    nc=len(df[df['Enjoy sport']=='no'])\n",
    "    n=len(df)\n",
    "    i,j,k,l=df.columns[:-1]\n",
    "    vsb=(yc/n)*prob(i,s,'yes')*prob(j,c,'yes')*prob(k,h,'yes')*prob(l,m,'yes')\n",
    "    vnb=(yc/n)*prob(i,s,'no')*prob(j,c,'no')*prob(k,h,'no')*prob(l,m,'no')\n",
    "    print(vsb)\n",
    "    print(vnb)\n",
    "    if vsb>vnb:\n",
    "        print(vsb)\n",
    "        print(\"is going to play\")\n",
    "    else:\n",
    "        print(vnb)\n",
    "        print(\"not going\")\n",
    "naive_bayes('sunny','cool','high','strong')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#16.Write the  Python code to compute Euclidean Distance between data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_dist(x1,x2,y1,y2):\n",
    "    dist=np.sqrt((x2-x1)**2+(y2-y1)**2)\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.830951894845301"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "euclidean_dist(3,6,8,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#17.Write the  Python code to calculate covariance matrix, Eigen values and Eigen vectors \n",
    "A = np.array([[9,2,3],[2,3,4],[9,5,2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigen vector [[-0.63566346 -0.4386726  -0.11958179]\n",
      " [-0.381541    0.85683887 -0.54787598]\n",
      " [-0.6710875   0.27091236  0.82796867]]\n",
      "eigen value [13.36763265  3.24077366 -2.60840631]\n"
     ]
    }
   ],
   "source": [
    "w,v = np.linalg.eig(A)\n",
    "print('eigen vector',v)\n",
    "print('eigen value',w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[14.33333333, -3.        , 11.16666667],\n",
       "       [-3.        ,  1.        , -3.5       ],\n",
       "       [11.16666667, -3.5       , 12.33333333]])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.cov(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "A=np.array([1,5,4,7,9,6])\n",
    "B=np.array([2,9,7,4,1,6])\n",
    "a=A.mean()\n",
    "b=B.mean()\n",
    "covAB=np.sum((A-a)*(B-b))\n",
    "covBA=covAB\n",
    "covAA=np.sum((A-a)**2)\n",
    "covBB=np.sum((B-b)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[37.33333333, -6.66666667],\n",
       "       [-6.66666667, 46.83333333]])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([[covAA,covAB],[covBA,covBB]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 5, 4, 4]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "400"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#apply PAC for the given data set \n",
    "df3=pd.read_csv(\"sport1.csv\")\n",
    "df3=df3.iloc[:,1:]\n",
    "n=[]\n",
    "for i in range(len(df3.columns)-1):\n",
    "    k=df3.iloc[:,i].unique()\n",
    "    n.append(len(k)+2)#y +2    \n",
    "print(n)\n",
    "Hs=np.prod(n)\n",
    "Hs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples required is :  259.3156856932418\n"
     ]
    }
   ],
   "source": [
    "def num_train_eg(hs,D,E):\n",
    "    m=(1/E)*(np.log10(hs)/np.log10(2)+np.log10(1/D)/np.log10(2))\n",
    "    return m\n",
    "print(\"Number of training examples required is : \",num_train_eg(Hs,0.05,0.05))\n",
    "#E-true error D-traing error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples required is :  259.3156856932418\n"
     ]
    }
   ],
   "source": [
    "#agnestic\n",
    "def train_req(hs,D,E):\n",
    "    m=(1/(2*(E**2)))*(np.log10(hs)/np.log10(2)+np.log10(1/D)/np.log10(2))\n",
    "    return m\n",
    "print(\"Number of training examples required is : \",num_train_eg(Hs,0.05,0.05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
